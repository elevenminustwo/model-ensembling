{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "parallel-multi-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpStbnLk0ZU"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "import tensorflow as tf\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization,Dropout,GlobalAveragePooling2D\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#from keras.applications.efficientnet import EfficientNetB0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d6XZ3sWH55F"
      },
      "source": [
        "seed_value = 1234\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "#tf deterministic ops just in case"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusodIgSmyCb",
        "outputId": "c4ce7d43-8f77-4c33-9ffc-3ff719886751"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgf_dddLlRcS"
      },
      "source": [
        "no_classes = 10\n",
        "img_width, img_height, img_num_channels = 32, 32, 3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qzBW4esmoiE"
      },
      "source": [
        "(input_train, target_train), (input_test, target_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dZ8aLY5mwZ5"
      },
      "source": [
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQz32CLNq4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda0bb4d-b931-4a23-e02f-e8ad44c24fcc"
      },
      "source": [
        "modelseq = Sequential()\n",
        "modelseq.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "modelseq.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Flatten())\n",
        "modelseq.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "modelseq.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# summarize layers\n",
        "print(modelseq.summary())\n",
        "# plot graph\n",
        "#plot_model(modelseq, to_file='modelseq.png')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNJ7JSOn45y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f3a1aa-eb9f-4602-cc99-0c3a96830043"
      },
      "source": [
        "# first model\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# second model\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# third model\n",
        "model4 = Sequential()\n",
        "model4.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "opt2 = keras.optimizers.Adam(learning_rate=0.01)\n",
        "opt3 = SGD(lr=0.001, momentum=0.9)\n",
        "model2.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer=opt2, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model4.compile(optimizer=opt3, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summarize layers\n",
        "print(model2.summary())\n",
        "print(model3.summary())\n",
        "print(model4.summary())\n",
        "# plot graph\n",
        "#plot_model(model2, to_file='model2.png')\n",
        "#plot_model(model3, to_file='model3.png')\n",
        "#plot_model(model4, to_file='model4.png')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 551,466\n",
            "Trainable params: 551,018\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 357,706\n",
            "Trainable params: 357,258\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16777344  \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 16,872,778\n",
            "Trainable params: 16,872,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5gbmz0lroPj6",
        "outputId": "3967668c-82b7-4664-872f-28608543808c"
      },
      "source": [
        "\"\"\"\n",
        "history = modelseq.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=25,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory = modelseq.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=25,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHwXFrlURgzK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ac4e4a99-20cd-4529-9953-b4b220d39077"
      },
      "source": [
        "\"\"\"\n",
        "history2 = model2.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory2 = model2.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz373YVqRj-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7dde8553-f39c-49dd-994e-abfc8c688d95"
      },
      "source": [
        "\"\"\"\n",
        "history3 = model3.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory3 = model3.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbp-L5zURmfH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "166f9a03-aff9-4cfe-9f48-3118ce28bf19"
      },
      "source": [
        "\"\"\"\n",
        "history4 = model4.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory4 = model4.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkQkkLRuo7_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "c891a9a5-0184-4325-a3a8-9ef58149de5e"
      },
      "source": [
        "\"\"\"\n",
        "# Generate generalization metrics\n",
        "score = modelseq.evaluate(input_test, target_test, verbose=0)\n",
        "score2 = model2.evaluate(input_test, target_test, verbose=0)\n",
        "score3 = model3.evaluate(input_test, target_test, verbose=0)\n",
        "score4 = model4.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "print(f'Test loss: {score2[0]} / Test accuracy: {score2[1]}')\n",
        "print(f'Test loss: {score3[0]} / Test accuracy: {score3[1]}')\n",
        "print(f'Test loss: {score4[0]} / Test accuracy: {score4[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['accuracy'],label = 'train_1')\n",
        "plt.plot(history.history['val_accuracy'],label = 'test_1')\n",
        "plt.plot(history2.history['accuracy'],label = 'train_2')\n",
        "plt.plot(history2.history['val_accuracy'],label = 'test_2')\n",
        "plt.plot(history3.history['accuracy'],label = 'train_3')\n",
        "plt.plot(history3.history['val_accuracy'],label = 'test_3')\n",
        "plt.plot(history4.history['accuracy'],label = 'train_4')\n",
        "plt.plot(history4.history['val_accuracy'],label = 'test_4')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Generate generalization metrics\\nscore = modelseq.evaluate(input_test, target_test, verbose=0)\\nscore2 = model2.evaluate(input_test, target_test, verbose=0)\\nscore3 = model3.evaluate(input_test, target_test, verbose=0)\\nscore4 = model4.evaluate(input_test, target_test, verbose=0)\\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\\nprint(f'Test loss: {score2[0]} / Test accuracy: {score2[1]}')\\nprint(f'Test loss: {score3[0]} / Test accuracy: {score3[1]}')\\nprint(f'Test loss: {score4[0]} / Test accuracy: {score4[1]}')\\n\\n# Visualize history\\n# Plot history: Loss\\nplt.plot(history.history['accuracy'],label = 'train_1')\\nplt.plot(history.history['val_accuracy'],label = 'test_1')\\nplt.plot(history2.history['accuracy'],label = 'train_2')\\nplt.plot(history2.history['val_accuracy'],label = 'test_2')\\nplt.plot(history3.history['accuracy'],label = 'train_3')\\nplt.plot(history3.history['val_accuracy'],label = 'test_3')\\nplt.plot(history4.history['accuracy'],label = 'train_4')\\nplt.plot(history4.history['val_accuracy'],label = 'test_4')\\nplt.legend()\\nplt.show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v51PvLXxtp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "07b1c4e4-8ee6-45d3-ab32-00eb13b3f552"
      },
      "source": [
        "\"\"\"\n",
        "#print(input_test[1])\n",
        "single = np.expand_dims(input_test[250], axis=0)\n",
        "prediction1 = modelseq.predict(input_test)\n",
        "prediction2 = model2.predict(input_test)\n",
        "prediction3 = model3.predict(input_test)\n",
        "prediction4 = model4.predict(input_test)\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#print(input_test[1])\\nsingle = np.expand_dims(input_test[250], axis=0)\\nprediction1 = modelseq.predict(input_test)\\nprediction2 = model2.predict(input_test)\\nprediction3 = model3.predict(input_test)\\nprediction4 = model4.predict(input_test)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "4V3KDqzBwKmp",
        "outputId": "c679525d-5d2a-414f-b652-ccce88cdfaa8"
      },
      "source": [
        "\"\"\"\n",
        "inception_model = EfficientNetB0(include_top=True,input_tensor=Input(shape=(32, 32, 3)))\n",
        "x = inception_model.output\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "#for layer in inception_model.layers:\n",
        "#    layer.trainable = False\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=5,restore_best_weights=True)\n",
        "optAdam = keras.optimizers.Adam(learning_rate=0.1)\n",
        "modified_inc =  Model(inputs=inception_model.input, outputs=predictions)\n",
        "modified_inc.compile(optimizer=optAdam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#print(input_train.shape)\n",
        "history_inc = modified_inc.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=100,\n",
        "            verbose=1,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[callback])\n",
        "\"\"\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ninception_model = EfficientNetB0(include_top=True,input_tensor=Input(shape=(32, 32, 3)))\\nx = inception_model.output\\npredictions = Dense(10, activation='softmax')(x)\\n\\n# i.e. freeze all convolutional InceptionV3 layers\\n#for layer in inception_model.layers:\\n#    layer.trainable = False\\n\\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=5,restore_best_weights=True)\\noptAdam = keras.optimizers.Adam(learning_rate=0.1)\\nmodified_inc =  Model(inputs=inception_model.input, outputs=predictions)\\nmodified_inc.compile(optimizer=optAdam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\\n\\n#print(input_train.shape)\\nhistory_inc = modified_inc.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=100,\\n            verbose=1,\\n            validation_split=0.2,\\n            callbacks=[callback])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beb9unGMs5Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e80ab6-2cec-436b-edc6-21fa8995372c"
      },
      "source": [
        "scores = list()\n",
        "scores.append(0.8094)\n",
        "scores.append(0.8209)\n",
        "scores.append(0.7386)\n",
        "scores.append(0.6340)\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=10,restore_best_weights=True)\n",
        "\n",
        "keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            modelseq,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "\n",
        "keras_clf2 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model2,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "keras_clf3 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model3,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "keras_clf4 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model4,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "\n",
        "keras_clf._estimator_type = \"classifier\"\n",
        "keras_clf2._estimator_type = \"classifier\"\n",
        "keras_clf3._estimator_type = \"classifier\"\n",
        "keras_clf4._estimator_type = \"classifier\"\n",
        "\n",
        "models = list()\t\n",
        "models.append(('m1', keras_clf))\n",
        "models.append(('m2', keras_clf2))\n",
        "models.append(('m3', keras_clf3))\n",
        "models.append(('m4', keras_clf4))\n",
        "\n",
        "# create the ensemble\n",
        "ensemble = VotingClassifier(estimators=models, voting='soft', weights=scores)\n",
        "# fit the ensemble on the training dataset\n",
        "ensemble.fit(input_train,target_train.ravel())\n",
        "# make predictions on test set\n",
        "yhat = ensemble.predict(input_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "625/625 [==============================] - 22s 10ms/step - loss: 2.1577 - accuracy: 0.1917 - val_loss: 1.6997 - val_accuracy: 0.3762\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.7138 - accuracy: 0.3619 - val_loss: 1.5324 - val_accuracy: 0.4497\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.5712 - accuracy: 0.4224 - val_loss: 1.3950 - val_accuracy: 0.5087\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.4573 - accuracy: 0.4687 - val_loss: 1.3388 - val_accuracy: 0.5228\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.3892 - accuracy: 0.4958 - val_loss: 1.2392 - val_accuracy: 0.5648\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.3192 - accuracy: 0.5232 - val_loss: 1.2067 - val_accuracy: 0.5706\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.2600 - accuracy: 0.5456 - val_loss: 1.1404 - val_accuracy: 0.5957\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.2089 - accuracy: 0.5670 - val_loss: 1.1060 - val_accuracy: 0.6081\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.1563 - accuracy: 0.5900 - val_loss: 1.0475 - val_accuracy: 0.6299\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.1179 - accuracy: 0.5970 - val_loss: 1.0112 - val_accuracy: 0.6440\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.0916 - accuracy: 0.6089 - val_loss: 1.0014 - val_accuracy: 0.6472\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 1.0682 - accuracy: 0.6179 - val_loss: 0.9574 - val_accuracy: 0.6635\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.0203 - accuracy: 0.6391 - val_loss: 0.9136 - val_accuracy: 0.6795\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.9835 - accuracy: 0.6525 - val_loss: 0.9171 - val_accuracy: 0.6753\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.9529 - accuracy: 0.6614 - val_loss: 0.8813 - val_accuracy: 0.6906\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.9398 - accuracy: 0.6719 - val_loss: 0.8591 - val_accuracy: 0.6962\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.9143 - accuracy: 0.6759 - val_loss: 0.8408 - val_accuracy: 0.7053\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.8798 - accuracy: 0.6866 - val_loss: 0.8241 - val_accuracy: 0.7076\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.8664 - accuracy: 0.6942 - val_loss: 0.8089 - val_accuracy: 0.7120\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.8526 - accuracy: 0.6970 - val_loss: 0.7910 - val_accuracy: 0.7228\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.8376 - accuracy: 0.7048 - val_loss: 0.7529 - val_accuracy: 0.7318\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.8091 - accuracy: 0.7139 - val_loss: 0.8130 - val_accuracy: 0.7108\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.8137 - accuracy: 0.7123 - val_loss: 0.7592 - val_accuracy: 0.7307\n",
            "Epoch 24/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.7725 - accuracy: 0.7263 - val_loss: 0.7509 - val_accuracy: 0.7317\n",
            "Epoch 25/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.7664 - accuracy: 0.7270 - val_loss: 0.7090 - val_accuracy: 0.7531\n",
            "Epoch 26/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.7421 - accuracy: 0.7366 - val_loss: 0.7041 - val_accuracy: 0.7517\n",
            "Epoch 27/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.7431 - accuracy: 0.7384 - val_loss: 0.7115 - val_accuracy: 0.7490\n",
            "Epoch 28/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7184 - accuracy: 0.7452 - val_loss: 0.6957 - val_accuracy: 0.7528\n",
            "Epoch 29/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7131 - accuracy: 0.7505 - val_loss: 0.7031 - val_accuracy: 0.7504\n",
            "Epoch 30/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6918 - accuracy: 0.7543 - val_loss: 0.7138 - val_accuracy: 0.7442\n",
            "Epoch 31/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6804 - accuracy: 0.7566 - val_loss: 0.6722 - val_accuracy: 0.7674\n",
            "Epoch 32/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6709 - accuracy: 0.7609 - val_loss: 0.6886 - val_accuracy: 0.7517\n",
            "Epoch 33/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6635 - accuracy: 0.7648 - val_loss: 0.6519 - val_accuracy: 0.7690\n",
            "Epoch 34/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6549 - accuracy: 0.7655 - val_loss: 0.6624 - val_accuracy: 0.7657\n",
            "Epoch 35/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6491 - accuracy: 0.7706 - val_loss: 0.6417 - val_accuracy: 0.7716\n",
            "Epoch 36/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6391 - accuracy: 0.7747 - val_loss: 0.6282 - val_accuracy: 0.7796\n",
            "Epoch 37/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6232 - accuracy: 0.7802 - val_loss: 0.6307 - val_accuracy: 0.7782\n",
            "Epoch 38/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6089 - accuracy: 0.7860 - val_loss: 0.6531 - val_accuracy: 0.7718\n",
            "Epoch 39/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6078 - accuracy: 0.7828 - val_loss: 0.6182 - val_accuracy: 0.7851\n",
            "Epoch 40/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6032 - accuracy: 0.7841 - val_loss: 0.6121 - val_accuracy: 0.7861\n",
            "Epoch 41/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5803 - accuracy: 0.7953 - val_loss: 0.6290 - val_accuracy: 0.7805\n",
            "Epoch 42/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.5705 - accuracy: 0.7979 - val_loss: 0.6040 - val_accuracy: 0.7899\n",
            "Epoch 43/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5610 - accuracy: 0.8001 - val_loss: 0.6159 - val_accuracy: 0.7845\n",
            "Epoch 44/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5652 - accuracy: 0.7973 - val_loss: 0.6074 - val_accuracy: 0.7898\n",
            "Epoch 45/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5538 - accuracy: 0.8022 - val_loss: 0.5960 - val_accuracy: 0.7935\n",
            "Epoch 46/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5348 - accuracy: 0.8096 - val_loss: 0.5799 - val_accuracy: 0.8018\n",
            "Epoch 47/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.5250 - accuracy: 0.8133 - val_loss: 0.5987 - val_accuracy: 0.7965\n",
            "Epoch 48/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5300 - accuracy: 0.8105 - val_loss: 0.5794 - val_accuracy: 0.8047\n",
            "Epoch 49/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5088 - accuracy: 0.8165 - val_loss: 0.5990 - val_accuracy: 0.7970\n",
            "Epoch 50/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.5029 - accuracy: 0.8242 - val_loss: 0.5758 - val_accuracy: 0.8038\n",
            "Epoch 51/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4983 - accuracy: 0.8225 - val_loss: 0.5841 - val_accuracy: 0.8002\n",
            "Epoch 52/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4895 - accuracy: 0.8263 - val_loss: 0.5682 - val_accuracy: 0.8034\n",
            "Epoch 53/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4971 - accuracy: 0.8210 - val_loss: 0.5980 - val_accuracy: 0.7994\n",
            "Epoch 54/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4739 - accuracy: 0.8295 - val_loss: 0.5835 - val_accuracy: 0.8054\n",
            "Epoch 55/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4723 - accuracy: 0.8299 - val_loss: 0.6047 - val_accuracy: 0.7965\n",
            "Epoch 56/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4719 - accuracy: 0.8306 - val_loss: 0.5502 - val_accuracy: 0.8139\n",
            "Epoch 57/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4547 - accuracy: 0.8348 - val_loss: 0.5562 - val_accuracy: 0.8111\n",
            "Epoch 58/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4467 - accuracy: 0.8410 - val_loss: 0.5537 - val_accuracy: 0.8114\n",
            "Epoch 59/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4403 - accuracy: 0.8424 - val_loss: 0.5623 - val_accuracy: 0.8114\n",
            "Epoch 60/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4396 - accuracy: 0.8414 - val_loss: 0.5559 - val_accuracy: 0.8104\n",
            "Epoch 61/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4278 - accuracy: 0.8461 - val_loss: 0.5794 - val_accuracy: 0.8051\n",
            "Epoch 62/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4233 - accuracy: 0.8491 - val_loss: 0.5548 - val_accuracy: 0.8124\n",
            "Epoch 63/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4184 - accuracy: 0.8504 - val_loss: 0.5642 - val_accuracy: 0.8167\n",
            "Epoch 64/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4146 - accuracy: 0.8502 - val_loss: 0.5636 - val_accuracy: 0.8150\n",
            "Epoch 65/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4034 - accuracy: 0.8572 - val_loss: 0.5684 - val_accuracy: 0.8118\n",
            "Epoch 66/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4012 - accuracy: 0.8560 - val_loss: 0.5765 - val_accuracy: 0.8114\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00066: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 10s 10ms/step - loss: 1.9444 - accuracy: 0.3136 - val_loss: 1.5375 - val_accuracy: 0.4391\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 1.2970 - accuracy: 0.5375 - val_loss: 1.2332 - val_accuracy: 0.5651\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 1.0449 - accuracy: 0.6294 - val_loss: 1.2359 - val_accuracy: 0.5891\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.8819 - accuracy: 0.6939 - val_loss: 0.8164 - val_accuracy: 0.7125\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.7905 - accuracy: 0.7223 - val_loss: 0.7718 - val_accuracy: 0.7278\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.6995 - accuracy: 0.7545 - val_loss: 0.8321 - val_accuracy: 0.7224\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.6444 - accuracy: 0.7751 - val_loss: 0.6873 - val_accuracy: 0.7674\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.5863 - accuracy: 0.7954 - val_loss: 0.6476 - val_accuracy: 0.7818\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5303 - accuracy: 0.8176 - val_loss: 0.6579 - val_accuracy: 0.7820\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.4964 - accuracy: 0.8253 - val_loss: 0.6742 - val_accuracy: 0.7769\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.4595 - accuracy: 0.8376 - val_loss: 0.6325 - val_accuracy: 0.7950\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.4184 - accuracy: 0.8556 - val_loss: 0.6302 - val_accuracy: 0.8027\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3989 - accuracy: 0.8575 - val_loss: 0.6465 - val_accuracy: 0.7892\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3658 - accuracy: 0.8722 - val_loss: 0.6687 - val_accuracy: 0.8007\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3498 - accuracy: 0.8771 - val_loss: 0.5971 - val_accuracy: 0.8087\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3244 - accuracy: 0.8863 - val_loss: 0.6196 - val_accuracy: 0.8062\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.3044 - accuracy: 0.8922 - val_loss: 0.6864 - val_accuracy: 0.7939\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2840 - accuracy: 0.8999 - val_loss: 0.6458 - val_accuracy: 0.8116\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2715 - accuracy: 0.9036 - val_loss: 0.7028 - val_accuracy: 0.8045\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2708 - accuracy: 0.9058 - val_loss: 0.6229 - val_accuracy: 0.8199\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2500 - accuracy: 0.9120 - val_loss: 0.5969 - val_accuracy: 0.8237\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2382 - accuracy: 0.9165 - val_loss: 0.6307 - val_accuracy: 0.8166\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2372 - accuracy: 0.9183 - val_loss: 0.6374 - val_accuracy: 0.8277\n",
            "Epoch 24/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2253 - accuracy: 0.9207 - val_loss: 0.7138 - val_accuracy: 0.8117\n",
            "Epoch 25/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2065 - accuracy: 0.9278 - val_loss: 0.7350 - val_accuracy: 0.8150\n",
            "Epoch 26/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1946 - accuracy: 0.9322 - val_loss: 0.6438 - val_accuracy: 0.8181\n",
            "Epoch 27/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1985 - accuracy: 0.9305 - val_loss: 0.6305 - val_accuracy: 0.8322\n",
            "Epoch 28/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2042 - accuracy: 0.9305 - val_loss: 0.9121 - val_accuracy: 0.7713\n",
            "Epoch 29/500\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1926 - accuracy: 0.9325 - val_loss: 0.6867 - val_accuracy: 0.8243\n",
            "Epoch 30/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1735 - accuracy: 0.9411 - val_loss: 0.6461 - val_accuracy: 0.8248\n",
            "Epoch 31/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1816 - accuracy: 0.9370 - val_loss: 0.6320 - val_accuracy: 0.8351\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 2.2701 - accuracy: 0.2527 - val_loss: 1.7084 - val_accuracy: 0.3638\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.5168 - accuracy: 0.4388 - val_loss: 2.2389 - val_accuracy: 0.3434\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.3389 - accuracy: 0.5159 - val_loss: 1.4220 - val_accuracy: 0.4880\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2172 - accuracy: 0.5727 - val_loss: 1.1905 - val_accuracy: 0.5875\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1476 - accuracy: 0.6020 - val_loss: 1.1430 - val_accuracy: 0.5992\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0805 - accuracy: 0.6272 - val_loss: 0.9925 - val_accuracy: 0.6578\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0506 - accuracy: 0.6391 - val_loss: 1.0426 - val_accuracy: 0.6525\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0329 - accuracy: 0.6429 - val_loss: 1.3186 - val_accuracy: 0.5779\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0092 - accuracy: 0.6599 - val_loss: 1.3364 - val_accuracy: 0.5835\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9822 - accuracy: 0.6641 - val_loss: 0.8913 - val_accuracy: 0.7030\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9602 - accuracy: 0.6789 - val_loss: 1.0158 - val_accuracy: 0.6571\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9544 - accuracy: 0.6771 - val_loss: 0.9232 - val_accuracy: 0.7141\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9505 - accuracy: 0.6784 - val_loss: 0.9458 - val_accuracy: 0.6862\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9159 - accuracy: 0.6889 - val_loss: 0.8213 - val_accuracy: 0.7314\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8897 - accuracy: 0.6980 - val_loss: 0.9230 - val_accuracy: 0.7120\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9028 - accuracy: 0.6964 - val_loss: 0.9712 - val_accuracy: 0.6768\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8827 - accuracy: 0.7057 - val_loss: 0.9427 - val_accuracy: 0.6850\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8742 - accuracy: 0.7050 - val_loss: 1.1774 - val_accuracy: 0.6096\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8740 - accuracy: 0.7073 - val_loss: 1.0196 - val_accuracy: 0.6745\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8653 - accuracy: 0.7100 - val_loss: 1.0435 - val_accuracy: 0.6844\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8566 - accuracy: 0.7116 - val_loss: 1.2215 - val_accuracy: 0.6614\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8561 - accuracy: 0.7140 - val_loss: 0.9532 - val_accuracy: 0.6829\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8594 - accuracy: 0.7154 - val_loss: 0.8531 - val_accuracy: 0.7301\n",
            "Epoch 24/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8424 - accuracy: 0.7246 - val_loss: 0.8357 - val_accuracy: 0.7320\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 16s 24ms/step - loss: 1.8371 - accuracy: 0.3633 - val_loss: 1.4890 - val_accuracy: 0.5034\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 1.2502 - accuracy: 0.5491 - val_loss: 1.2979 - val_accuracy: 0.5657\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 1.0387 - accuracy: 0.6282 - val_loss: 1.2280 - val_accuracy: 0.5910\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.8714 - accuracy: 0.6880 - val_loss: 1.2114 - val_accuracy: 0.6138\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.7409 - accuracy: 0.7360 - val_loss: 1.1651 - val_accuracy: 0.6340\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.6130 - accuracy: 0.7817 - val_loss: 1.1866 - val_accuracy: 0.6398\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.5198 - accuracy: 0.8151 - val_loss: 1.3213 - val_accuracy: 0.6262\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.4337 - accuracy: 0.8463 - val_loss: 1.2745 - val_accuracy: 0.6521\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.3594 - accuracy: 0.8741 - val_loss: 1.3047 - val_accuracy: 0.6473\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.2985 - accuracy: 0.8973 - val_loss: 1.5136 - val_accuracy: 0.6305\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2683 - accuracy: 0.9078 - val_loss: 1.3759 - val_accuracy: 0.6577\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2291 - accuracy: 0.9207 - val_loss: 1.3935 - val_accuracy: 0.6648\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2000 - accuracy: 0.9318 - val_loss: 1.4045 - val_accuracy: 0.6632\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1738 - accuracy: 0.9398 - val_loss: 1.4694 - val_accuracy: 0.6638\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1578 - accuracy: 0.9471 - val_loss: 1.5289 - val_accuracy: 0.6701\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "157/157 [==============================] - 1s 3ms/step\n",
            "157/157 [==============================] - 1s 3ms/step\n",
            "157/157 [==============================] - 1s 2ms/step\n",
            "157/157 [==============================] - 1s 6ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPy9iNl4-7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bf7160-a9e8-4fad-dda6-8b1e2d93e43c"
      },
      "source": [
        "# evaluate predictions\n",
        "score = np.mean(yhat==np.squeeze(target_test))\n",
        "print(scores)\n",
        "print('Weighted Avg Accuracy: %.3f' % (score*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8094, 0.8209, 0.7386, 0.634]\n",
            "Weighted Avg Accuracy: 82.740\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}