{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "parallel-multi-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpStbnLk0ZU"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "import tensorflow as tf\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input,Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization,Dropout,GlobalAveragePooling2D\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#from keras.applications.efficientnet import EfficientNetB0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d6XZ3sWH55F"
      },
      "source": [
        "seed_value = 1234\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "#maybe tensorflow and tf differs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gusodIgSmyCb",
        "outputId": "b736ec54-a965-4874-bb78-9eaebc77a459"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgf_dddLlRcS"
      },
      "source": [
        "no_classes = 10\n",
        "img_width, img_height, img_num_channels = 32, 32, 3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qzBW4esmoiE"
      },
      "source": [
        "(input_train, target_train), (input_test, target_test) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dZ8aLY5mwZ5"
      },
      "source": [
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQz32CLNq4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8fe6212-251d-4397-e28a-3e2c22c4982f"
      },
      "source": [
        "modelseq = Sequential()\n",
        "modelseq.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "modelseq.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "modelseq.add(MaxPooling2D((2, 2)))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Flatten())\n",
        "modelseq.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "modelseq.add(Dropout(0.2))\n",
        "modelseq.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "modelseq.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# summarize layers\n",
        "print(modelseq.summary())\n",
        "# plot graph\n",
        "#plot_model(modelseq, to_file='modelseq.png')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 550,570\n",
            "Trainable params: 550,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNJ7JSOn45y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775178c2-8625-47ff-8433-0782a0085e28"
      },
      "source": [
        "# first model\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# second model\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPooling2D((2, 2)))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# third model\n",
        "model4 = Sequential()\n",
        "model4.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=input_shape))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model4.add(BatchNormalization())\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model4.add(Dropout(0.2))\n",
        "model4.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "opt2 = keras.optimizers.Adam(learning_rate=0.01)\n",
        "opt3 = SGD(lr=0.001, momentum=0.9)\n",
        "model2.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer=opt2, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model4.compile(optimizer=opt3, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# summarize layers\n",
        "print(model2.summary())\n",
        "print(model3.summary())\n",
        "print(model4.summary())\n",
        "# plot graph\n",
        "#plot_model(model2, to_file='model2.png')\n",
        "#plot_model(model3, to_file='model3.png')\n",
        "#plot_model(model4, to_file='model4.png')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 551,466\n",
            "Trainable params: 551,018\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 357,706\n",
            "Trainable params: 357,258\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 131072)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16777344  \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 16,872,778\n",
            "Trainable params: 16,872,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5gbmz0lroPj6",
        "outputId": "9581245a-5720-445b-92b0-41411405b2bf"
      },
      "source": [
        "\"\"\"\n",
        "history = modelseq.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=25,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory = modelseq.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=25,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHwXFrlURgzK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0dd99580-e805-4cd1-c425-b24c8334b947"
      },
      "source": [
        "\"\"\"\n",
        "history2 = model2.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory2 = model2.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz373YVqRj-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ae66a124-3cde-4565-d351-5502b7b40a21"
      },
      "source": [
        "\"\"\"\n",
        "history3 = model3.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory3 = model3.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbp-L5zURmfH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bed38668-6a1c-4526-9d47-40058149fb3f"
      },
      "source": [
        "\"\"\"\n",
        "history4 = model4.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=10,\n",
        "            verbose=1,\n",
        "            validation_split=0.2)\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory4 = model4.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=10,\\n            verbose=1,\\n            validation_split=0.2)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkQkkLRuo7_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "4f847f0b-7640-4ed9-8692-c4979b0ea2c8"
      },
      "source": [
        "\"\"\"\n",
        "# Generate generalization metrics\n",
        "score = modelseq.evaluate(input_test, target_test, verbose=0)\n",
        "score2 = model2.evaluate(input_test, target_test, verbose=0)\n",
        "score3 = model3.evaluate(input_test, target_test, verbose=0)\n",
        "score4 = model4.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "print(f'Test loss: {score2[0]} / Test accuracy: {score2[1]}')\n",
        "print(f'Test loss: {score3[0]} / Test accuracy: {score3[1]}')\n",
        "print(f'Test loss: {score4[0]} / Test accuracy: {score4[1]}')\n",
        "\n",
        "# Visualize history\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['accuracy'],label = 'train_1')\n",
        "plt.plot(history.history['val_accuracy'],label = 'test_1')\n",
        "plt.plot(history2.history['accuracy'],label = 'train_2')\n",
        "plt.plot(history2.history['val_accuracy'],label = 'test_2')\n",
        "plt.plot(history3.history['accuracy'],label = 'train_3')\n",
        "plt.plot(history3.history['val_accuracy'],label = 'test_3')\n",
        "plt.plot(history4.history['accuracy'],label = 'train_4')\n",
        "plt.plot(history4.history['val_accuracy'],label = 'test_4')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Generate generalization metrics\\nscore = modelseq.evaluate(input_test, target_test, verbose=0)\\nscore2 = model2.evaluate(input_test, target_test, verbose=0)\\nscore3 = model3.evaluate(input_test, target_test, verbose=0)\\nscore4 = model4.evaluate(input_test, target_test, verbose=0)\\nprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\\nprint(f'Test loss: {score2[0]} / Test accuracy: {score2[1]}')\\nprint(f'Test loss: {score3[0]} / Test accuracy: {score3[1]}')\\nprint(f'Test loss: {score4[0]} / Test accuracy: {score4[1]}')\\n\\n# Visualize history\\n# Plot history: Loss\\nplt.plot(history.history['accuracy'],label = 'train_1')\\nplt.plot(history.history['val_accuracy'],label = 'test_1')\\nplt.plot(history2.history['accuracy'],label = 'train_2')\\nplt.plot(history2.history['val_accuracy'],label = 'test_2')\\nplt.plot(history3.history['accuracy'],label = 'train_3')\\nplt.plot(history3.history['val_accuracy'],label = 'test_3')\\nplt.plot(history4.history['accuracy'],label = 'train_4')\\nplt.plot(history4.history['val_accuracy'],label = 'test_4')\\nplt.legend()\\nplt.show()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v51PvLXxtp4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2b2d6c6f-a2ea-4d6e-adce-12b55a652b8c"
      },
      "source": [
        "\"\"\"\n",
        "#print(input_test[1])\n",
        "single = np.expand_dims(input_test[250], axis=0)\n",
        "prediction1 = modelseq.predict(input_test)\n",
        "prediction2 = model2.predict(input_test)\n",
        "prediction3 = model3.predict(input_test)\n",
        "prediction4 = model4.predict(input_test)\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#print(input_test[1])\\nsingle = np.expand_dims(input_test[250], axis=0)\\nprediction1 = modelseq.predict(input_test)\\nprediction2 = model2.predict(input_test)\\nprediction3 = model3.predict(input_test)\\nprediction4 = model4.predict(input_test)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "4V3KDqzBwKmp",
        "outputId": "2436aad7-f1a7-4312-f3a6-a29b8c5f7c88"
      },
      "source": [
        "\"\"\"\n",
        "inception_model = EfficientNetB0(include_top=True,input_tensor=Input(shape=(32, 32, 3)))\n",
        "x = inception_model.output\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "#for layer in inception_model.layers:\n",
        "#    layer.trainable = False\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=5,restore_best_weights=True)\n",
        "optAdam = keras.optimizers.Adam(learning_rate=0.1)\n",
        "modified_inc =  Model(inputs=inception_model.input, outputs=predictions)\n",
        "modified_inc.compile(optimizer=optAdam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#print(input_train.shape)\n",
        "history_inc = modified_inc.fit(input_train, target_train,\n",
        "            batch_size=64,\n",
        "            epochs=100,\n",
        "            verbose=1,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[callback])\n",
        "\"\"\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ninception_model = EfficientNetB0(include_top=True,input_tensor=Input(shape=(32, 32, 3)))\\nx = inception_model.output\\npredictions = Dense(10, activation='softmax')(x)\\n\\n# i.e. freeze all convolutional InceptionV3 layers\\n#for layer in inception_model.layers:\\n#    layer.trainable = False\\n\\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=5,restore_best_weights=True)\\noptAdam = keras.optimizers.Adam(learning_rate=0.1)\\nmodified_inc =  Model(inputs=inception_model.input, outputs=predictions)\\nmodified_inc.compile(optimizer=optAdam, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\\n\\n#print(input_train.shape)\\nhistory_inc = modified_inc.fit(input_train, target_train,\\n            batch_size=64,\\n            epochs=100,\\n            verbose=1,\\n            validation_split=0.2,\\n            callbacks=[callback])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beb9unGMs5Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd6af11-bc56-497d-caf2-17782d29b2ce"
      },
      "source": [
        "scores = list()\n",
        "scores.append(0.8102)\n",
        "scores.append(0.8131)\n",
        "scores.append(0.6504)\n",
        "scores.append(0.6123)\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',verbose=1, patience=5,restore_best_weights=True)\n",
        "\n",
        "keras_clf = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            modelseq,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "\n",
        "keras_clf2 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model2,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "keras_clf3 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model3,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "keras_clf4 = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn = lambda:\n",
        "                            model4,\n",
        "                            batch_size=64,\n",
        "                            epochs=500,\n",
        "                            verbose=True,\n",
        "                            validation_split=0.2,\n",
        "                            callbacks=[callback])\n",
        "\n",
        "keras_clf._estimator_type = \"classifier\"\n",
        "keras_clf2._estimator_type = \"classifier\"\n",
        "keras_clf3._estimator_type = \"classifier\"\n",
        "keras_clf4._estimator_type = \"classifier\"\n",
        "\n",
        "models = list()\t\n",
        "models.append(('m1', keras_clf))\n",
        "models.append(('m2', keras_clf2))\n",
        "models.append(('m3', keras_clf3))\n",
        "models.append(('m4', keras_clf4))\n",
        "\n",
        "# create the ensemble\n",
        "ensemble = VotingClassifier(estimators=models, voting='soft', weights=scores)\n",
        "# fit the ensemble on the training dataset\n",
        "ensemble.fit(input_train,target_train.ravel())\n",
        "# make predictions on test set\n",
        "yhat = ensemble.predict(input_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "625/625 [==============================] - 20s 9ms/step - loss: 2.1559 - accuracy: 0.1920 - val_loss: 1.7112 - val_accuracy: 0.3713\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.7130 - accuracy: 0.3601 - val_loss: 1.5316 - val_accuracy: 0.4518\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.5649 - accuracy: 0.4231 - val_loss: 1.3981 - val_accuracy: 0.5050\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.4534 - accuracy: 0.4702 - val_loss: 1.3293 - val_accuracy: 0.5260\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.3839 - accuracy: 0.5002 - val_loss: 1.2418 - val_accuracy: 0.5653\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.3201 - accuracy: 0.5245 - val_loss: 1.2178 - val_accuracy: 0.5699\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.2559 - accuracy: 0.5459 - val_loss: 1.1359 - val_accuracy: 0.5999\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.2072 - accuracy: 0.5690 - val_loss: 1.1052 - val_accuracy: 0.6093\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.1550 - accuracy: 0.5919 - val_loss: 1.0457 - val_accuracy: 0.6358\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.1172 - accuracy: 0.5980 - val_loss: 1.0107 - val_accuracy: 0.6431\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.0921 - accuracy: 0.6097 - val_loss: 0.9968 - val_accuracy: 0.6464\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.0625 - accuracy: 0.6218 - val_loss: 0.9566 - val_accuracy: 0.6626\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 1.0209 - accuracy: 0.6386 - val_loss: 0.9331 - val_accuracy: 0.6745\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.9785 - accuracy: 0.6532 - val_loss: 0.9126 - val_accuracy: 0.6799\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.9506 - accuracy: 0.6677 - val_loss: 0.8691 - val_accuracy: 0.6968\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.9390 - accuracy: 0.6678 - val_loss: 0.8719 - val_accuracy: 0.6895\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.9131 - accuracy: 0.6749 - val_loss: 0.8297 - val_accuracy: 0.7071\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8795 - accuracy: 0.6880 - val_loss: 0.8131 - val_accuracy: 0.7124\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8690 - accuracy: 0.6923 - val_loss: 0.8111 - val_accuracy: 0.7153\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8549 - accuracy: 0.6966 - val_loss: 0.7971 - val_accuracy: 0.7178\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8383 - accuracy: 0.7051 - val_loss: 0.7559 - val_accuracy: 0.7322\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8109 - accuracy: 0.7142 - val_loss: 0.8105 - val_accuracy: 0.7140\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.8149 - accuracy: 0.7086 - val_loss: 0.7563 - val_accuracy: 0.7333\n",
            "Epoch 24/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7712 - accuracy: 0.7289 - val_loss: 0.7308 - val_accuracy: 0.7443\n",
            "Epoch 25/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7730 - accuracy: 0.7231 - val_loss: 0.7076 - val_accuracy: 0.7511\n",
            "Epoch 26/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7437 - accuracy: 0.7363 - val_loss: 0.7064 - val_accuracy: 0.7508\n",
            "Epoch 27/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7410 - accuracy: 0.7385 - val_loss: 0.6977 - val_accuracy: 0.7558\n",
            "Epoch 28/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7223 - accuracy: 0.7447 - val_loss: 0.6923 - val_accuracy: 0.7546\n",
            "Epoch 29/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.7164 - accuracy: 0.7470 - val_loss: 0.7204 - val_accuracy: 0.7457\n",
            "Epoch 30/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6982 - accuracy: 0.7561 - val_loss: 0.6980 - val_accuracy: 0.7526\n",
            "Epoch 31/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6848 - accuracy: 0.7597 - val_loss: 0.6753 - val_accuracy: 0.7639\n",
            "Epoch 32/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6711 - accuracy: 0.7617 - val_loss: 0.7049 - val_accuracy: 0.7496\n",
            "Epoch 33/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6672 - accuracy: 0.7633 - val_loss: 0.6443 - val_accuracy: 0.7751\n",
            "Epoch 34/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6488 - accuracy: 0.7732 - val_loss: 0.6506 - val_accuracy: 0.7696\n",
            "Epoch 35/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6438 - accuracy: 0.7741 - val_loss: 0.6343 - val_accuracy: 0.7795\n",
            "Epoch 36/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6396 - accuracy: 0.7719 - val_loss: 0.6269 - val_accuracy: 0.7783\n",
            "Epoch 37/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6235 - accuracy: 0.7779 - val_loss: 0.6256 - val_accuracy: 0.7808\n",
            "Epoch 38/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6117 - accuracy: 0.7830 - val_loss: 0.6393 - val_accuracy: 0.7785\n",
            "Epoch 39/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6034 - accuracy: 0.7839 - val_loss: 0.6046 - val_accuracy: 0.7902\n",
            "Epoch 40/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.6016 - accuracy: 0.7861 - val_loss: 0.6135 - val_accuracy: 0.7865\n",
            "Epoch 41/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5821 - accuracy: 0.7931 - val_loss: 0.6155 - val_accuracy: 0.7869\n",
            "Epoch 42/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5739 - accuracy: 0.7953 - val_loss: 0.6123 - val_accuracy: 0.7870\n",
            "Epoch 43/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5666 - accuracy: 0.8005 - val_loss: 0.6117 - val_accuracy: 0.7887\n",
            "Epoch 44/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5661 - accuracy: 0.7982 - val_loss: 0.5931 - val_accuracy: 0.7926\n",
            "Epoch 45/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5473 - accuracy: 0.8038 - val_loss: 0.5908 - val_accuracy: 0.7981\n",
            "Epoch 46/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5382 - accuracy: 0.8090 - val_loss: 0.5870 - val_accuracy: 0.7960\n",
            "Epoch 47/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5289 - accuracy: 0.8144 - val_loss: 0.6206 - val_accuracy: 0.7895\n",
            "Epoch 48/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5307 - accuracy: 0.8100 - val_loss: 0.5787 - val_accuracy: 0.7970\n",
            "Epoch 49/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5069 - accuracy: 0.8178 - val_loss: 0.5828 - val_accuracy: 0.7991\n",
            "Epoch 50/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5097 - accuracy: 0.8177 - val_loss: 0.5671 - val_accuracy: 0.8010\n",
            "Epoch 51/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.5000 - accuracy: 0.8210 - val_loss: 0.5634 - val_accuracy: 0.8070\n",
            "Epoch 52/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4916 - accuracy: 0.8272 - val_loss: 0.5670 - val_accuracy: 0.8061\n",
            "Epoch 53/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4934 - accuracy: 0.8251 - val_loss: 0.5964 - val_accuracy: 0.7986\n",
            "Epoch 54/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4761 - accuracy: 0.8300 - val_loss: 0.5670 - val_accuracy: 0.8061\n",
            "Epoch 55/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4673 - accuracy: 0.8314 - val_loss: 0.6297 - val_accuracy: 0.7886\n",
            "Epoch 56/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4710 - accuracy: 0.8321 - val_loss: 0.5497 - val_accuracy: 0.8104\n",
            "Epoch 57/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4567 - accuracy: 0.8368 - val_loss: 0.5619 - val_accuracy: 0.8082\n",
            "Epoch 58/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4508 - accuracy: 0.8360 - val_loss: 0.5566 - val_accuracy: 0.8114\n",
            "Epoch 59/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4525 - accuracy: 0.8380 - val_loss: 0.5692 - val_accuracy: 0.8101\n",
            "Epoch 60/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4363 - accuracy: 0.8439 - val_loss: 0.5499 - val_accuracy: 0.8141\n",
            "Epoch 61/500\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4274 - accuracy: 0.8485 - val_loss: 0.5792 - val_accuracy: 0.8041\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00061: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 10s 10ms/step - loss: 1.9373 - accuracy: 0.3189 - val_loss: 1.6770 - val_accuracy: 0.4273\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.3031 - accuracy: 0.5340 - val_loss: 1.4378 - val_accuracy: 0.5314\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 1.0433 - accuracy: 0.6278 - val_loss: 0.8681 - val_accuracy: 0.6930\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.8754 - accuracy: 0.6932 - val_loss: 0.7677 - val_accuracy: 0.7294\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.7923 - accuracy: 0.7262 - val_loss: 0.7744 - val_accuracy: 0.7323\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.6895 - accuracy: 0.7603 - val_loss: 0.7030 - val_accuracy: 0.7607\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6234 - accuracy: 0.7797 - val_loss: 0.6869 - val_accuracy: 0.7639\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5686 - accuracy: 0.8001 - val_loss: 0.6532 - val_accuracy: 0.7804\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.5260 - accuracy: 0.8148 - val_loss: 0.6547 - val_accuracy: 0.7851\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4794 - accuracy: 0.8314 - val_loss: 0.6608 - val_accuracy: 0.7872\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4338 - accuracy: 0.8471 - val_loss: 0.6289 - val_accuracy: 0.7973\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4117 - accuracy: 0.8563 - val_loss: 0.6090 - val_accuracy: 0.8067\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.3872 - accuracy: 0.8650 - val_loss: 0.6325 - val_accuracy: 0.7998\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.3597 - accuracy: 0.8738 - val_loss: 0.6068 - val_accuracy: 0.8151\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.3364 - accuracy: 0.8817 - val_loss: 0.6315 - val_accuracy: 0.8128\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.3189 - accuracy: 0.8880 - val_loss: 0.6409 - val_accuracy: 0.8124\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2982 - accuracy: 0.8953 - val_loss: 0.6574 - val_accuracy: 0.8038\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2733 - accuracy: 0.9057 - val_loss: 0.6844 - val_accuracy: 0.8042\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2677 - accuracy: 0.9094 - val_loss: 0.5759 - val_accuracy: 0.8249\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2604 - accuracy: 0.9091 - val_loss: 0.6173 - val_accuracy: 0.8202\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2450 - accuracy: 0.9122 - val_loss: 0.6280 - val_accuracy: 0.8185\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2373 - accuracy: 0.9172 - val_loss: 0.6669 - val_accuracy: 0.8109\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2390 - accuracy: 0.9163 - val_loss: 0.6930 - val_accuracy: 0.8129\n",
            "Epoch 24/500\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2128 - accuracy: 0.9253 - val_loss: 0.6947 - val_accuracy: 0.8192\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 2.2427 - accuracy: 0.2749 - val_loss: 2.6182 - val_accuracy: 0.2070\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.4735 - accuracy: 0.4622 - val_loss: 1.2934 - val_accuracy: 0.5222\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2938 - accuracy: 0.5370 - val_loss: 1.4074 - val_accuracy: 0.5139\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2120 - accuracy: 0.5713 - val_loss: 1.0677 - val_accuracy: 0.6322\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.1423 - accuracy: 0.6042 - val_loss: 1.1329 - val_accuracy: 0.6039\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.0917 - accuracy: 0.6220 - val_loss: 1.0248 - val_accuracy: 0.6495\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0679 - accuracy: 0.6310 - val_loss: 1.0754 - val_accuracy: 0.6434\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.0340 - accuracy: 0.6456 - val_loss: 0.9172 - val_accuracy: 0.6860\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 1.0200 - accuracy: 0.6498 - val_loss: 1.0831 - val_accuracy: 0.6374\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9878 - accuracy: 0.6606 - val_loss: 0.8676 - val_accuracy: 0.7115\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.9838 - accuracy: 0.6661 - val_loss: 0.9758 - val_accuracy: 0.6702\n",
            "Epoch 12/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9656 - accuracy: 0.6750 - val_loss: 0.8830 - val_accuracy: 0.7076\n",
            "Epoch 13/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9601 - accuracy: 0.6743 - val_loss: 0.8532 - val_accuracy: 0.7258\n",
            "Epoch 14/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9095 - accuracy: 0.6887 - val_loss: 1.0797 - val_accuracy: 0.6615\n",
            "Epoch 15/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.9023 - accuracy: 0.6894 - val_loss: 0.8714 - val_accuracy: 0.7073\n",
            "Epoch 16/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9146 - accuracy: 0.6907 - val_loss: 0.9675 - val_accuracy: 0.6817\n",
            "Epoch 17/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.9036 - accuracy: 0.6966 - val_loss: 0.9526 - val_accuracy: 0.6887\n",
            "Epoch 18/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.8976 - accuracy: 0.6989 - val_loss: 0.8047 - val_accuracy: 0.7322\n",
            "Epoch 19/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8733 - accuracy: 0.7029 - val_loss: 0.9088 - val_accuracy: 0.7016\n",
            "Epoch 20/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8684 - accuracy: 0.7073 - val_loss: 0.8393 - val_accuracy: 0.7218\n",
            "Epoch 21/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8631 - accuracy: 0.7087 - val_loss: 0.9841 - val_accuracy: 0.6852\n",
            "Epoch 22/500\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.8523 - accuracy: 0.7131 - val_loss: 0.9071 - val_accuracy: 0.6978\n",
            "Epoch 23/500\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.8516 - accuracy: 0.7109 - val_loss: 0.8771 - val_accuracy: 0.7238\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "Epoch 1/500\n",
            "625/625 [==============================] - 16s 23ms/step - loss: 1.8385 - accuracy: 0.3634 - val_loss: 1.5310 - val_accuracy: 0.4815\n",
            "Epoch 2/500\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 1.2512 - accuracy: 0.5533 - val_loss: 1.3462 - val_accuracy: 0.5562\n",
            "Epoch 3/500\n",
            "625/625 [==============================] - 13s 21ms/step - loss: 1.0460 - accuracy: 0.6276 - val_loss: 1.2230 - val_accuracy: 0.5875\n",
            "Epoch 4/500\n",
            "625/625 [==============================] - 13s 22ms/step - loss: 0.8813 - accuracy: 0.6857 - val_loss: 1.2081 - val_accuracy: 0.6119\n",
            "Epoch 5/500\n",
            "625/625 [==============================] - 13s 22ms/step - loss: 0.7441 - accuracy: 0.7345 - val_loss: 1.2218 - val_accuracy: 0.6227\n",
            "Epoch 6/500\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.6143 - accuracy: 0.7789 - val_loss: 1.1910 - val_accuracy: 0.6322\n",
            "Epoch 7/500\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.5279 - accuracy: 0.8102 - val_loss: 1.1973 - val_accuracy: 0.6439\n",
            "Epoch 8/500\n",
            "625/625 [==============================] - 13s 22ms/step - loss: 0.4222 - accuracy: 0.8514 - val_loss: 1.2613 - val_accuracy: 0.6544\n",
            "Epoch 9/500\n",
            "625/625 [==============================] - 13s 22ms/step - loss: 0.3609 - accuracy: 0.8718 - val_loss: 1.3362 - val_accuracy: 0.6472\n",
            "Epoch 10/500\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.3002 - accuracy: 0.8982 - val_loss: 1.7080 - val_accuracy: 0.6170\n",
            "Epoch 11/500\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.2656 - accuracy: 0.9069 - val_loss: 1.4032 - val_accuracy: 0.6592\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "157/157 [==============================] - 1s 3ms/step\n",
            "157/157 [==============================] - 1s 3ms/step\n",
            "157/157 [==============================] - 1s 2ms/step\n",
            "157/157 [==============================] - 1s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPy9iNl4-7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09f187c5-381b-41ce-8ef4-5ac763c75195"
      },
      "source": [
        "# evaluate predictions\n",
        "score = np.mean(yhat==np.squeeze(target_test))\n",
        "print(scores)\n",
        "print('Weighted Avg Accuracy: %.3f' % (score*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8102, 0.8131, 0.6504, 0.6123]\n",
            "Weighted Avg Accuracy: 82.560\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}